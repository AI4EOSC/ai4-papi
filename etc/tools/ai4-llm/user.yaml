---
# User customizable configuration to make a deployment in Nomad.
# Additional non-customizable values (eg. ports) are hardcoded in `job.nomad`.

# All conf parameters follow the same structure:
# varname:
#  name: name of the parameter to be displayed to end user (mandatory)
#  value: (default) value of the parameter (mandatory)
#  options: restricted set of values that the parameter can take (optional)
#  description: some comments on the parameter to be displayed to the end user (optional)


general:

  title:
    name: Deployment title
    value: ''
    description: Provide short title for this deployment (less than 45 characters). Useful when you have lots of different active deployments.

  desc:
    name: Deployment description
    value: ''
    description: Provide some additional extended information about this deployment.

  type:
    name: Deployment type
    value: 'both'
    description: Type of the deployment. For example `llm`.
    options: [
      'vllm',
      'open-webui',
      'both'
    ]

  docker_image:
    name: Docker image
    value: 'vllm/vllm-openai'
    description: Docker image to be used. For example `deephdc/deep-oc-image-classification-tf`.

  docker_tag:
    name: Docker tag
    value: 'latest'
    description: Docker tag to use. Tags are module dependent. You should choose the appropriate tag for your selected hardware (eg. use a `gpu`-like tag if you plan to run on GPUs).
    options: ['latest']


vllm:
  
  gpu_memory_utilization:
    name: GPU memory utilization 
    value: 1
    range: [0, 1]
    description: Fraction of GPU memory to be used. 

  max_model_len:
    name: Maximum model length
    value: 
    description: Maximum length of the model.
    
  tensor_parrallel_size:
    name: Tensor parrallel size
    value: 1
    description: Number of tensor parrallel size.